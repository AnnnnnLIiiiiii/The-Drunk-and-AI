# The-Drunk-and-AI
HRI Project: A conceptual prototype of HGN self-testing mobile application

(A project in Human-Robot Interaction)

According to the statistic number from U.S. Department of Transportation in 2017, 29 people die in motor vehicle crashes that involve an alcohol-impaired driver every day; in 2016, 10,497 people died in alcohol-impaired driving crashes, accounting for 28% of all traffic-related deaths in the United States; one over three of drivers are involved in a DUI instance either as driver or as a victim of a impaired driver.

The Standardized Field Sobriety Test (SFST) is a battery of 3 tests performed during a traffic stop in order to determine if a driver is impaired. The Horizontal Gaze Nystagmus (HGN), developed in the 1970s, is one of them that are scientifically validated, and are admissible as evidence in court in a majority of states. The accuracy is about 78-88%.

â€œNystagmus" generally refers to any bouncing or jerking of the eye. Police officers are concerned only with horizontal gaze nystagmus, a completely involuntary motion that becomes more pronounced when an individual is impaired by alcohol. Usually, police officer may use notable moving object, such as moving flash light left and right in front of a person to implement the test.

This project aims to reproduce HGN by smart phones, because a smart phone usually consists of flash light and camera, which enable the smart phone to take a picture or record a video about a person's eyes movement during flash light moving in front of him or her.

The project try to integrate machine learning with facial features recognition, OpenCV and Android Studio 5.0 Lollipop on Python to develop a prototype of Horizontal Gaze Nystagmus (HGN) self-testing mobile application. By using this app, a user will obtain test data (his or her eyes movement of tracing moving flash light) and send it to a server that is already trained, and receive the result of his or her drunk level.
